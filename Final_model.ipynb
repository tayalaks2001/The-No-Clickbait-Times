{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsData = pd.read_csv(\"train.csv\")\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "#removing all rows with unspecified label\n",
    "newsData = newsData[newsData.label != 'other']\n",
    "#Cleaning the remaining data\n",
    "newsData = newsData.dropna(axis=0)\n",
    "newsData.reset_index(drop=True, inplace=True)\n",
    "#Cleaning test data\n",
    "testData = testData[[\"title\",\"text\"]]\n",
    "testData.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newsData.title\n",
    "y = newsData.label\n",
    "for i in range(18330):\n",
    "  if y[i]=='clickbait':\n",
    "    y[i]=True\n",
    "  else:\n",
    "    y[i]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype('bool')\n",
    "\n",
    "clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,3), min_df=0.001)),\n",
    "                ('clf', MultinomialNB())])\n",
    "clf = clf.fit(X, y)\n",
    "y_test_title_pred = clf.predict(testData.title)\n",
    "\n",
    "X = newsData.text\n",
    "clf = clf.fit(X, y)\n",
    "y_test_text_pred = clf.predict(testData.text)\n",
    "\n",
    "y_test_pred = pd.DataFrame(y_test_title_pred | y_test_text_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors,Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "# To tokenize the string into words\n",
    "def tokenizing(ss1,ss2):\n",
    "    sentence1 = word_tokenize(ss1)\n",
    "    sentence2 = word_tokenize(ss2)\n",
    "    return sentence1,sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the data : remove non alphanumeric characters\n",
    "def cleaning(sentence1,sentence2):\n",
    "    cleaned_ss1=[]\n",
    "    for i in sentence1:\n",
    "        if (i not in stopWords) and (i.isalnum()) :\n",
    "            cleaned_ss1.append(i)\n",
    "\n",
    "    cleaned_ss2=[]\n",
    "    for i in sentence2:\n",
    "        if i not in stopWords and i.isalnum():\n",
    "            cleaned_ss2.append(i)\n",
    "    return cleaned_ss1,cleaned_ss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first function with a self defined formula to check if two sentences are related or similar\n",
    "def check_spam(cleaned_ss1,cleaned_ss2):\n",
    "    count = 0\n",
    "    for i in cleaned_ss1:\n",
    "        for j in cleaned_ss2:\n",
    "            try:\n",
    "                if model.similarity(i,j)>=0.3 :\n",
    "                    count+=1\n",
    "            except:\n",
    "                pass\n",
    "    if count>=(len(cleaned_ss1)*len(cleaned_ss2))**0.5:\n",
    "        spam = False\n",
    "    else :\n",
    "        spam = True\n",
    "    return spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the norm(magnitude) of the vector\n",
    "def magnitude(vector):\n",
    "    sum_of_squares = 0\n",
    "    k=0\n",
    "    for num in vector:\n",
    "        sum_of_squares += (num*num)\n",
    "        k+=1\n",
    "    result = sum_of_squares**0.5\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the dot product of two vectors\n",
    "def dot_product(u,v):\n",
    "    dot = 0\n",
    "    k=0\n",
    "    for num in v:\n",
    "        dot+=u[k]*v[k]\n",
    "        k=k+1\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second function to check if two sentences are similar\n",
    "def double_check(cleaned_ss1, cleaned_ss2):\n",
    "    tolerance = 0.3\n",
    "    v = [0]\n",
    "    for i in cleaned_ss1:\n",
    "        try:\n",
    "            v = v + model[i]\n",
    "        except:\n",
    "            pass\n",
    "    u = [0]\n",
    "    for i in cleaned_ss2:\n",
    "        try:\n",
    "            u = u + model[i]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if (magnitude(u) == 0 or magnitude(v) == 0):\n",
    "        spam = True\n",
    "        cosine = 0\n",
    "    else:\n",
    "        cosine = dot_product(u, v) / (magnitude(v) * magnitude(u))\n",
    "        if (cosine > tolerance):\n",
    "            spam = False\n",
    "        else:\n",
    "            spam = True\n",
    "    return spam\n",
    "\n",
    "\n",
    "# Third function to check if two sentences are similar or not\n",
    "def triple_check(cleaned_ss1, cleaned_ss2):\n",
    "    tolerance = 1.5\n",
    "    v = [0]\n",
    "    for i in cleaned_ss1:\n",
    "        try:\n",
    "            v = v + model[i]\n",
    "        except:\n",
    "            pass\n",
    "    u = [0]\n",
    "    for i in cleaned_ss2:\n",
    "        try:\n",
    "            u = u + model[i]\n",
    "        except:\n",
    "            pass\n",
    "    diff = magnitude(u) - magnitude(v)\n",
    "\n",
    "    if (-tolerance <= diff <= tolerance):\n",
    "        spam = False\n",
    "    else:\n",
    "        spam = True\n",
    "    return spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from summarizer import Summarizer\n",
    "model = Summarizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-5cdb773b5240>\", line 3, in <module>\n",
      "    orig_summary = model(testData['text'][i], ratio=0.05, min_length=6)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 1068, in __getitem__\n",
      "    result = self.index.get_value(self, key)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 4730, in get_value\n",
      "    return self._engine.get_value(s, k, tz=getattr(series.dtype, \"tz\", None))\n",
      "  File \"pandas\\_libs\\index.pyx\", line 80, in pandas._libs.index.IndexEngine.get_value\n",
      "  File \"pandas\\_libs\\index.pyx\", line 88, in pandas._libs.index.IndexEngine.get_value\n",
      "  File \"pandas\\_libs\\index.pyx\", line 131, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 992, in pandas._libs.hashtable.Int64HashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 998, in pandas._libs.hashtable.Int64HashTable.get_item\n",
      "KeyError: 361\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-5cdb773b5240>\", line 3, in <module>\n",
      "    orig_summary = model(testData['text'][i], ratio=0.05, min_length=6)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 1068, in __getitem__\n",
      "    result = self.index.get_value(self, key)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 4730, in get_value\n",
      "    return self._engine.get_value(s, k, tz=getattr(series.dtype, \"tz\", None))\n",
      "  File \"pandas\\_libs\\index.pyx\", line 80, in pandas._libs.index.IndexEngine.get_value\n",
      "  File \"pandas\\_libs\\index.pyx\", line 88, in pandas._libs.index.IndexEngine.get_value\n",
      "  File \"pandas\\_libs\\index.pyx\", line 131, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 992, in pandas._libs.hashtable.Int64HashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 998, in pandas._libs.hashtable.Int64HashTable.get_item\n",
      "KeyError: 361\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Kiran\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "361",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    if y_test_pred[0][i]:\n",
    "        orig_summary = model(testData['text'][i], ratio=0.05, min_length=6)\n",
    "        orig_summary = ''.join(orig_summary)\n",
    "        orig_headline = testData[\"title\"][i]\n",
    "        headline = orig_headline.lower()\n",
    "        summary = orig_summary.lower()\n",
    "        headline, summary = tokenizing(headline, summary)\n",
    "        headline, summary = cleaning(headline, summary)\n",
    "        check1 = check_spam(headline, summary)\n",
    "        check2 = double_check(headline, summary)\n",
    "        check3 = triple_check(headline, summary)\n",
    "        if (check1 and check2) or (check2 and check3) or(check1 and check3):  # at least 2 are true\n",
    "            testData[\"title\"][i] = orig_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
